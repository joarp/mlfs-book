{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1f2881-7273-45ff-9259-537b23ad8ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Root dir: c:\\Users\\lulev\\Desktop\\KTH\\mlfs-book\n",
      "Added the following directory to the PYTHONPATH: c:\\Users\\lulev\\Desktop\\KTH\\mlfs-book\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` \n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6a80c",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f447120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from mlfs.airquality import util\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50156f96",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1a49d6-9cd2-4246-b0ca-1058672e4848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-15 11:53:19,193 INFO: Initializing external client\n",
      "2025-11-15 11:53:19,194 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-15 11:53:20,956 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279155\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login(engine=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f651f0",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> Load parameters of all cities </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e7dfabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Load all parameters for each city\n",
    "def load_city(csv_path):\n",
    "    city_dict = {}\n",
    "    with open(csv_path, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            city = row[\"city\"].strip().lower()\n",
    "            url = row[\"url\"].strip()\n",
    "            latitude = row[\"latitude\"].strip()\n",
    "            longitude = row[\"longitude\"].strip()\n",
    "            # Can use the below line instead if long & lat is unknown, but I got blocked from the ost API :(\n",
    "            # latitude, longitude = util.get_city_coordinates(city)\n",
    "            csv_file=f\"{root_dir}/data/{city}.csv\"\n",
    "            city_dict[city] = {\n",
    "                \"url\": url,\n",
    "                \"csv_file\": csv_file,\n",
    "                \"latitude\": float(latitude),\n",
    "                \"longitude\": float(longitude)\n",
    "            }\n",
    "    return city_dict\n",
    "\n",
    "city_dict = load_city(f\"{root_dir}/data/urls.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39d548",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> Get AQICN API KEY </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9145f0b7-d961-41f7-aebe-741dbf00784c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found AQICN_API_KEY: 4b11809c8f7e83cc9bfe296a4324433b0a0055ba\n",
      "Replacing existing AQICN_API_KEY\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Secret('AQICN_API_KEY', 'PRIVATE')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = datetime.date.today()\n",
    "# taken from ~/.env. You can also replace settings.AQICN_API_KEY with the api key value as a string \"....\"\n",
    "if settings.AQICN_API_KEY is None:\n",
    "    print(\"You need to set AQICN_API_KEY either in this cell or in ~/.env\")\n",
    "    sys.exit(1)\n",
    "AQICN_API_KEY = settings.AQICN_API_KEY.get_secret_value()\n",
    "\n",
    "print(f\"Found AQICN_API_KEY: {AQICN_API_KEY}\")\n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "# Replace any existing secret with the new value\n",
    "secret = secrets.get_secret(\"AQICN_API_KEY\")\n",
    "if secret is not None:\n",
    "    secret.delete()\n",
    "    print(\"Replacing existing AQICN_API_KEY\")\n",
    "\n",
    "secrets.create_secret(\"AQICN_API_KEY\", AQICN_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca9105",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> The parameters of all cities currently in use </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d127b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bodo': {'url': 'https://api.waqi.info/feed/@12706',\n",
       "  'csv_file': 'c:\\\\Users\\\\lulev\\\\Desktop\\\\KTH\\\\mlfs-book/data/bodo.csv',\n",
       "  'latitude': 67.28,\n",
       "  'longitude': 14.38},\n",
       " 'moirana': {'url': 'https://api.waqi.info/feed/@12698',\n",
       "  'csv_file': 'c:\\\\Users\\\\lulev\\\\Desktop\\\\KTH\\\\mlfs-book/data/moirana.csv',\n",
       "  'latitude': 66.33,\n",
       "  'longitude': 14.18}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "786127b0-c4e5-4a5f-a6fa-4cce903a9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     aq_today_df = util.get_pm25(aqicn_url, city, today, AQICN_API_KEY)\n",
    "# except hopsworks.RestAPIError:\n",
    "#     print(\"It looks like the AQICN_API_KEY doesn't work for your sensor. Is the API key correct? Is the sensor URL correct?\")\n",
    "\n",
    "# aq_today_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706e751",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> Read CSV file into a DataFrame </span>\n",
    "\n",
    "The cell below will read up historical air quality data as a CSV file into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc3a1212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>pm10</th>\n",
       "      <th>city</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4228 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  pm25  pm10     city                                url\n",
       "0    2025-11-01  10.0   4.0     bodo  https://api.waqi.info/feed/@12706\n",
       "1    2025-11-02   4.0  11.0     bodo  https://api.waqi.info/feed/@12706\n",
       "2    2025-11-03   8.0   6.0     bodo  https://api.waqi.info/feed/@12706\n",
       "3    2025-11-04   6.0   9.0     bodo  https://api.waqi.info/feed/@12706\n",
       "4    2025-11-05  21.0   4.0     bodo  https://api.waqi.info/feed/@12706\n",
       "...         ...   ...   ...      ...                                ...\n",
       "4223 2020-01-04   NaN   8.0  moirana  https://api.waqi.info/feed/@12698\n",
       "4224 2020-01-05   NaN   8.0  moirana  https://api.waqi.info/feed/@12698\n",
       "4225 2020-01-06   NaN  11.0  moirana  https://api.waqi.info/feed/@12698\n",
       "4226 2020-01-07   NaN  10.0  moirana  https://api.waqi.info/feed/@12698\n",
       "4227 2020-01-08   NaN  10.0  moirana  https://api.waqi.info/feed/@12698\n",
       "\n",
       "[4228 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = []\n",
    "for city in city_dict:  \n",
    "    df_temp = pd.read_csv(city_dict[city][\"csv_file\"],  parse_dates=['date'], skipinitialspace=True)\n",
    "    df_temp[\"city\"] = city\n",
    "    df_temp[\"url\"] = city_dict[city][\"url\"]\n",
    "    df_list.append(df_temp)\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812eb37-04e3-4291-8d77-a69ef7a195bc",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>Data cleaning</span>\n",
    "\n",
    "\n",
    "### Rename columns if needed and drop unneccessary columns\n",
    "\n",
    "We want to have a DataFrame with 2 columns - `date`, `pm25`, `city`, `url` after this cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcfa73",
   "metadata": {},
   "source": [
    "## Check the data types for the columns in your DataFrame\n",
    "\n",
    " * `date` should be of type   datetime64[ns] \n",
    " * `pm25` should be of type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd20c859-ef3c-4b54-bbcb-83898afefa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>city</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>8.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>6.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>21.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4228 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  pm25     city                                url\n",
       "0    2025-11-01  10.0     bodo  https://api.waqi.info/feed/@12706\n",
       "1    2025-11-02   4.0     bodo  https://api.waqi.info/feed/@12706\n",
       "2    2025-11-03   8.0     bodo  https://api.waqi.info/feed/@12706\n",
       "3    2025-11-04   6.0     bodo  https://api.waqi.info/feed/@12706\n",
       "4    2025-11-05  21.0     bodo  https://api.waqi.info/feed/@12706\n",
       "...         ...   ...      ...                                ...\n",
       "4223 2020-01-04   NaN  moirana  https://api.waqi.info/feed/@12698\n",
       "4224 2020-01-05   NaN  moirana  https://api.waqi.info/feed/@12698\n",
       "4225 2020-01-06   NaN  moirana  https://api.waqi.info/feed/@12698\n",
       "4226 2020-01-07   NaN  moirana  https://api.waqi.info/feed/@12698\n",
       "4227 2020-01-08   NaN  moirana  https://api.waqi.info/feed/@12698\n",
       "\n",
       "[4228 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aq = df[['date', 'pm25', 'city', 'url']]\n",
    "df_aq['pm25'] = df_aq['pm25'].astype('float32')\n",
    "\n",
    "df_aq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f13a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4228 entries, 0 to 4227\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    4228 non-null   datetime64[ns]\n",
      " 1   pm25    4208 non-null   float32       \n",
      " 2   city    4228 non-null   object        \n",
      " 3   url     4228 non-null   object        \n",
      "dtypes: datetime64[ns](1), float32(1), object(2)\n",
      "memory usage: 115.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Cast the pm25 column to be a float32 data type\n",
    "df_aq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19911f73",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>Drop any rows with missing data </span>\n",
    "It will make the model training easier if there is no missing data in the rows, so we drop any rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37b0a762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pm25</th>\n",
       "      <th>city</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>8.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-04</td>\n",
       "      <td>6.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>21.0</td>\n",
       "      <td>bodo</td>\n",
       "      <td>https://api.waqi.info/feed/@12706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>11.0</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>2020-03-28</td>\n",
       "      <td>11.0</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>9.0</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4210</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>21.0</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>20.0</td>\n",
       "      <td>moirana</td>\n",
       "      <td>https://api.waqi.info/feed/@12698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4208 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  pm25     city                                url\n",
       "0    2025-11-01  10.0     bodo  https://api.waqi.info/feed/@12706\n",
       "1    2025-11-02   4.0     bodo  https://api.waqi.info/feed/@12706\n",
       "2    2025-11-03   8.0     bodo  https://api.waqi.info/feed/@12706\n",
       "3    2025-11-04   6.0     bodo  https://api.waqi.info/feed/@12706\n",
       "4    2025-11-05  21.0     bodo  https://api.waqi.info/feed/@12706\n",
       "...         ...   ...      ...                                ...\n",
       "4207 2020-03-27  11.0  moirana  https://api.waqi.info/feed/@12698\n",
       "4208 2020-03-28  11.0  moirana  https://api.waqi.info/feed/@12698\n",
       "4209 2020-03-29   9.0  moirana  https://api.waqi.info/feed/@12698\n",
       "4210 2020-03-30  21.0  moirana  https://api.waqi.info/feed/@12698\n",
       "4211 2020-03-31  20.0  moirana  https://api.waqi.info/feed/@12698\n",
       "\n",
       "[4208 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aq.dropna(inplace=True)\n",
    "# df_aq[\"lag1\"] = df_aq[\"pm25\"].shift(1)\n",
    "# df_aq[\"lag2\"] = df_aq[\"pm25\"].shift(2)\n",
    "# df_aq[\"lag3\"] = df_aq[\"pm25\"].shift(3)\n",
    "# df_aq[\"rolling\"] = (df_aq.set_index(\"date\")[\"pm25\"].rolling(window=3).mean().reset_index(drop=True))\n",
    "df_aq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c6dc05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4208 entries, 0 to 4211\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    4208 non-null   datetime64[ns]\n",
      " 1   pm25    4208 non-null   float32       \n",
      " 2   city    4208 non-null   object        \n",
      " 3   url     4208 non-null   object        \n",
      "dtypes: datetime64[ns](1), float32(1), object(2)\n",
      "memory usage: 147.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_aq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000e8276",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055befa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Loading Weather Data from [Open Meteo](https://open-meteo.com/en/docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78686a28",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>Download the Historical Weather Data </span>\n",
    "\n",
    "https://open-meteo.com/en/docs/historical-weather-api#hourly=&daily=temperature_2m_mean,precipitation_sum,wind_speed_10m_max,wind_direction_10m_dominant\n",
    "\n",
    "We will download the historical weather data for your `city` by first extracting the earliest date from your DataFrame containing the historical air quality measurements.\n",
    "\n",
    "We will download all daily historical weather data measurements for your `city` from the earliest date in your air quality measurement DataFrame. It doesn't matter if there are missing days of air quality measurements. We can store all of the daily weather measurements, and when we build our training dataset, we will join up the air quality measurements for a given day to its weather features for that day. \n",
    "\n",
    "The weather features we will download are:\n",
    "\n",
    " * `temperature (average over the day)`\n",
    " * `precipitation (the total over the day)`\n",
    " * `wind speed (average over the day)`\n",
    " * `wind direction (the most dominant direction over the day)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96d604b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 67.31107330322266¬∞N 14.587156295776367¬∞E\n",
      "Elevation 18.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n",
      "Coordinates 66.32688903808594¬∞N 13.988268852233887¬∞E\n",
      "Elevation 18.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    }
   ],
   "source": [
    "earliest_aq_date = pd.Series.min(df_aq['date'])\n",
    "earliest_aq_date = earliest_aq_date.strftime('%Y-%m-%d')\n",
    "earliest_aq_date\n",
    "\n",
    "weather_df_list = []\n",
    "for city in city_dict:\n",
    "    temp_weather_df = util.get_historical_weather(city, earliest_aq_date, str(today), city_dict[city][\"latitude\"], city_dict[city][\"longitude\"])\n",
    "    weather_df_list.append(temp_weather_df)\n",
    "weather_df = pd.concat(weather_df_list, ignore_index=True)\n",
    "\n",
    "weather_df.loc[weather_df[\"city\"] == \"selfors\", \"city\"] = \"moirana\" # Set the right city key since we used a different part of moirana for the weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd6eefe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4292 entries, 0 to 4291\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         4292 non-null   datetime64[ns]\n",
      " 1   temperature_2m_mean          4292 non-null   float32       \n",
      " 2   precipitation_sum            4292 non-null   float32       \n",
      " 3   wind_speed_10m_max           4292 non-null   float32       \n",
      " 4   wind_direction_10m_dominant  4292 non-null   float32       \n",
      " 5   city                         4292 non-null   object        \n",
      "dtypes: datetime64[ns](1), float32(4), object(1)\n",
      "memory usage: 134.2+ KB\n"
     ]
    }
   ],
   "source": [
    "weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9d5eeb",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'>Define Data Validation Rules </span>\n",
    "\n",
    "We will validate the air quality measurements (`pm25` values) before we write them to Hopsworks.\n",
    "\n",
    "We define a data validation rule (an expectation in Great Expectations) that ensures that `pm25` values are not negative or above the max value available by the sensor.\n",
    "\n",
    "We will attach this expectation to the air quality feature group, so that we validate the `pm25` data every time we write a DataFrame to the feature group. We want to prevent garbage-in, garbage-out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11bcdcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"expectation_type\": \"expect_column_min_to_be_between\", \"kwargs\": {\"column\": \"pm25\", \"min_value\": -0.1, \"max_value\": 500.0, \"strict_min\": true}, \"meta\": {}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import great_expectations as ge\n",
    "aq_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"aq_expectation_suite\"\n",
    ")\n",
    "\n",
    "aq_expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_min_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\":\"pm25\",\n",
    "            \"min_value\":-0.1,\n",
    "            \"max_value\":500.0,\n",
    "            \"strict_min\":True\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bef9ed3",
   "metadata": {},
   "source": [
    "## Expectations for Weather Data\n",
    "Here, we define an expectation for 2 columns in our weather DataFrame - `precipitation_sum` and `wind_speed_10m_max`, where we expect both values to be greater than zero, but less than 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bff8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "weather_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"weather_expectation_suite\"\n",
    ")\n",
    "\n",
    "def expect_greater_than_zero(col):\n",
    "    weather_expectation_suite.add_expectation(\n",
    "        ge.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_min_to_be_between\",\n",
    "            kwargs={\n",
    "                \"column\":col,\n",
    "                \"min_value\":-0.1,\n",
    "                \"max_value\":1000.0,\n",
    "                \"strict_min\":True\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "expect_greater_than_zero(\"precipitation_sum\")\n",
    "expect_greater_than_zero(\"wind_speed_10m_max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3830b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291a502",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ STEP 11: Connect to Hopsworks and save the sensor country, city, street names as a secret</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeaf20ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = project.get_feature_store() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd82f7",
   "metadata": {},
   "source": [
    "#### Save country, city, street names as a secret\n",
    "\n",
    "These will be downloaded from Hopsworks later in the (1) daily feature pipeline and (2) the daily batch inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd36749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing existing SENSOR_LOCATION_JSON\n",
      "Secret created successfully, explore it at https://c.app.hopsworks.ai:443/account/secrets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Secret('SENSOR_LOCATION_JSON', 'PRIVATE')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dictionary to a JSON string\n",
    "str_dict = json.dumps(city_dict)\n",
    "\n",
    "# Replace any existing secret with the new value\n",
    "secret = secrets.get_secret(\"SENSOR_LOCATION_JSON\")\n",
    "if secret is not None:\n",
    "    secret.delete()\n",
    "    print(\"Replacing existing SENSOR_LOCATION_JSON\")\n",
    "\n",
    "secrets.create_secret(\"SENSOR_LOCATION_JSON\", str_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e79b3f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">Create the Feature Groups and insert the DataFrames in them </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3755b6f",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üå´ Air Quality Data\n",
    "    \n",
    " 1. Provide a name, description, and version for the feature group.\n",
    " 2. Define the `primary_key`: we have to select which columns uniquely identify each row in the DataFrame - by providing them as the `primary_key`. Here, each air quality sensor measurement is uniquely identified by `country`, `street`, and  `date`.\n",
    " 3. Define the `event_time`: We also define which column stores the timestamp or date for the row - `date`.\n",
    " 4. Attach any `expectation_suite` containing data validation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d2bb403",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "air_quality_fg = fs.get_or_create_feature_group(\n",
    "    name='air_quality',\n",
    "    description='Air Quality characteristics of each day',\n",
    "    version=1,\n",
    "    primary_key=['city'],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=aq_expectation_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2933cfa5",
   "metadata": {},
   "source": [
    "#### Insert the DataFrame into the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fb42574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1279155/fs/1265766/fg/1718620\n",
      "2025-11-15 11:53:25,691 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279155/fs/1265766/fg/1718620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 4208/4208 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279155/jobs/named/air_quality_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('air_quality_1_offline_fg_materialization', 'SPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 758797\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 2.0,\n",
       "         \"element_count\": 4208,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-15T10:53:25.000691Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 1,\n",
       "     \"successful_expectations\": 1,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"aq_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2025-11-15T11:53:25.691033+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"4fc331ff-c211-11f0-8199-f854f6b41736\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20251115T105325.691033Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality_fg.insert(df_aq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a1606",
   "metadata": {},
   "source": [
    "#### Enter a description for each feature in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "577effca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x1c5e64ee710>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality_fg.update_feature_description(\"date\", \"Date of measurement of air quality\")\n",
    "air_quality_fg.update_feature_description(\"city\", \"City where the air quality was measured\")\n",
    "air_quality_fg.update_feature_description(\"pm25\", \"Particles less than 2.5 micrometers in diameter (fine particles) pose health risk\")\n",
    "# air_quality_fg.update_feature_description(\"lag1\", \"1 day lagged airquality measure\")\n",
    "# air_quality_fg.update_feature_description(\"lag2\", \"2 day lagged airquality measure\")\n",
    "# air_quality_fg.update_feature_description(\"lag3\", \"3 day lagged airquality measure\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5894b731",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üå¶ Weather Data\n",
    "    \n",
    " 1. Provide a name, description, and version for the feature group.\n",
    " 2. Define the `primary_key`: we have to select which columns uniquely identify each row in the DataFrame - by providing them as the `primary_key`. Here, each weather measurement is uniquely identified by `city` and  `date`.\n",
    " 3. Define the `event_time`: We also define which column stores the timestamp or date for the row - `date`.\n",
    " 4. Attach any `expectation_suite` containing data validation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "572a84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create feature group \n",
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name='weather',\n",
    "    description='Weather characteristics of each day',\n",
    "    version=1,\n",
    "    primary_key=['city'],\n",
    "    event_time=\"date\",\n",
    "    expectation_suite=weather_expectation_suite\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721881b7",
   "metadata": {},
   "source": [
    "#### Insert the DataFrame into the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ba846ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1279155/fs/1265766/fg/1718621\n",
      "2025-11-15 11:54:13,755 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279155/fs/1265766/fg/1718621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 4292/4292 | Elapsed Time: 00:02 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279155/jobs/named/weather_1_offline_fg_materialization/executions\n",
      "2025-11-15 11:54:31,423 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-15 11:54:34,603 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-15 11:56:19,631 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-11-15 11:56:19,794 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-15 11:56:28,433 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('weather_1_offline_fg_materialization', 'SPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"precipitation_sum\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 758798\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 0.0,\n",
       "         \"element_count\": 4292,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-15T10:54:13.000755Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"wind_speed_10m_max\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 758799\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 1.707629680633545,\n",
       "         \"element_count\": 4292,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-15T10:54:13.000755Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 2,\n",
       "     \"successful_expectations\": 2,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"weather_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2025-11-15T11:54:13.755380+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"6c693b8e-c211-11f0-af75-f854f6b41736\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20251115T105413.755380Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert data\n",
    "weather_fg.insert(weather_df, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87422d",
   "metadata": {},
   "source": [
    "#### Enter a description for each feature in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71e6f6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x1c5e69264d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_fg.update_feature_description(\"date\", \"Date of measurement of weather\")\n",
    "weather_fg.update_feature_description(\"city\", \"City where weather is measured/forecast for\")\n",
    "weather_fg.update_feature_description(\"temperature_2m_mean\", \"Temperature in Celsius\")\n",
    "weather_fg.update_feature_description(\"precipitation_sum\", \"Precipitation (rain/snow) in mm\")\n",
    "weather_fg.update_feature_description(\"wind_speed_10m_max\", \"Wind speed at 10m abouve ground\")\n",
    "weather_fg.update_feature_description(\"wind_direction_10m_dominant\", \"Dominant Wind direction over the dayd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc16b5",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 02: Daily Feature Pipeline \n",
    " </span> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c029117",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Exercises:** \n",
    " </span> \n",
    "\n",
    "Extra Homework:\n",
    "\n",
    "  * Try adding a new feature based on a rolling window of 3 days for 'pm25'\n",
    "      * This is not easy, as forecasting more than 1 day in the future, you won't have the previous 3 days of pm25 measurements.\n",
    "      * df.set_index(\"date\").rolling(3).mean() is only the start....\n",
    "  * Parameterize the notebook, so that you can provide the `country`/`street`/`city`/`url`/`csv_file` as parameters. \n",
    "      * Hint: this will also require making the secret name (`SENSOR_LOCATION_JSON`), e.g., add the street name as part of the secret name. Then you have to pass that secret name as a parameter when running the operational feature pipeline and batch inference pipelines.\n",
    "      * After you have done this, collect the street/city/url/csv files for all the sensors in your city or region and you make dashboards for all of the air quality sensors in your city/region. You could even then add a dashboard for your city/region, as done [here for Poland](https://github.com/erno98/ID2223).\n",
    "\n",
    "Improve this AI System\n",
    "  * As of mid 2024, there is no API call available to download historical data from the AQIN website. You could improve this system by writing a PR to download the CSV file using Python Selenium and the URL for the sensor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb407899",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
